{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import langextract as lx\n",
    "import textwrap\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbf660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up Google Gemini API Key \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get('LANGEXTRACT_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8734242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once\n",
    "\n",
    "!curl https://arxiv.org/pdf/1704.05842 -o jet_substructure_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell once\n",
    "!curl https://arxiv.org/pdf/2107.11405 -o stable_diffusion_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13446619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for paper 1\n",
    "doc = pymupdf.open('jet_substructure_paper.pdf')\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26eded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for paper 2\n",
    "doc2 = pymupdf.open('stable_diffusion_paper.pdf')\n",
    "\n",
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltext = \"\"\n",
    "for page in doc:\n",
    "    text = page.get_text()\n",
    "    alltext += text + \"\\n\"\n",
    "\n",
    "print(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34921f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltext = \"\"\n",
    "for page in doc2:\n",
    "    text = page.get_text()\n",
    "    alltext += text + \"\\n\"\n",
    "\n",
    "print(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49725d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define a concise prompt\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "\n",
    "Extract mentions of names of datasets, size in file counts, number of events and disk space size in bytes from scientific texts.\n",
    "Use exact text for extractions. Do not paraphrase. \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# 2. Provide a high-quality example to guide the model\n",
    "examples = [\n",
    "    lx.data.ExampleData(\n",
    "        text=(\n",
    "            \"Our jet substructure study is based on the Jet Primary Dataset [76], \"\n",
    "            \"which is a subset of the full open data release with events that pass a predefined set \"\n",
    "            \"of single-jet and multi-jet triggers. There are 1664 AOD files in the Jet Primary Dataset, corresponding to 20,022,826 events \"\n",
    "            \"and 2.0 Terabytes of disk space.\"\n",
    "        ),\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"file count\",\n",
    "                extraction_text=\"1664 AOD files\",\n",
    "                attributes={\"type\": \"count\"}, \n",
    "\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"data set\",\n",
    "                extraction_text=\"Jet Primary Dataset\",\n",
    "                attributes={\"type\": \"data set\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"disk space\",\n",
    "                extraction_text=\"2.0 Terabytes of disk space\",\n",
    "                attributes={\"type\": \"disk space\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"number of events\",\n",
    "                extraction_text=\"20,022,826 events\",\n",
    "                attributes={\"type\": \"count\"},\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "\n",
    "    # Additional diverse examples to improve robustness\n",
    "    lx.data.ExampleData(\n",
    "        text=(\n",
    "            \"The analysis uses an integrated sample from /MuonEG/Run2017C-31Mar2018-v1/AOD with roughly 4.5e5 events distributed over 320 files, \"\n",
    "            \"with an on-disk footprint of approximately 210 GiB (compressed).\"\n",
    "        ),\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"data set\",\n",
    "                extraction_text=\"/MuonEG/Run2017C-31Mar2018-v1/AOD\",\n",
    "                attributes={\"type\": \"data set\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"number of events\",\n",
    "                extraction_text=\"roughly 4.5e5 events\",\n",
    "                attributes={\"type\": \"count\", \"approx\": True},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"file count\",\n",
    "                extraction_text=\"320 files\",\n",
    "                attributes={\"type\": \"count\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"disk space\",\n",
    "                extraction_text=\"approximately 210 GiB (compressed)\",\n",
    "                attributes={\"type\": \"disk space\", \"units\": \"GiB\"},\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "\n",
    "    lx.data.ExampleData(\n",
    "        text=(\n",
    "            \"We processed 1.25 million events from Dataset_Z_v3 (internal name: DZ_v3) across 1,800 AOD files. The raw size was ~2.8 TB, reduced to ~700 GB after compression and archiving.\"\n",
    "        ),\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"data set\",\n",
    "                extraction_text=\"Dataset_Z_v3 (internal name: DZ_v3)\",\n",
    "                attributes={\"type\": \"data set\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"number of events\",\n",
    "                extraction_text=\"1.25 million events\",\n",
    "                attributes={\"type\": \"count\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"file count\",\n",
    "                extraction_text=\"1,800 AOD files\",\n",
    "                attributes={\"type\": \"count\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"disk space\",\n",
    "                extraction_text=\"raw size was ~2.8 TB, reduced to ~700 GB after compression and archiving\",\n",
    "                attributes={\"type\": \"disk space\"},\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "\n",
    "    lx.data.ExampleData(\n",
    "        text=(\n",
    "            \"The study analyzes a small specialized subset (Sample-Small) containing 2,340 events in 12 files; total disk usage is negligible (~15 MB) because the files are skimmed and only selected branches are kept.\"\n",
    "        ),\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"data set\",\n",
    "                extraction_text=\"Sample-Small\",\n",
    "                attributes={\"type\": \"data set\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"number of events\",\n",
    "                extraction_text=\"2,340 events\",\n",
    "                attributes={\"type\": \"count\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"file count\",\n",
    "                extraction_text=\"12 files\",\n",
    "                attributes={\"type\": \"count\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"disk space\",\n",
    "                extraction_text=\"~15 MB\",\n",
    "                attributes={\"type\": \"disk space\", \"units\": \"MB\"},\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 3. Run the extraction on your input text\n",
    "input_text = alltext\n",
    "\n",
    "\n",
    "result = lx.extract(\n",
    "    text_or_documents=input_text,\n",
    "    prompt_description=prompt,\n",
    "    examples=examples,\n",
    "    model_id=\"gemini-2.5-flash\",\n",
    "    api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and visualize the results\n",
    "lx.io.save_annotated_documents([result], output_name=\"jetsubstructureTest_extraction.jsonl\", output_dir=\".\")\n",
    "\n",
    "# Generate the interactive visualization\n",
    "html_content = lx.visualize(\"jetsubstructureTest_extraction.jsonl\")\n",
    "with open(\"jetsubstructureTest_extraction.html\", \"w\", encoding='utf-8') as f:\n",
    "    if hasattr(html_content, 'data'): #Check if the content has a data attribute\n",
    "        f.write(html_content.data)  \n",
    "    else:\n",
    "        f.write(html_content)\n",
    "\n",
    "print(\"Interactive visualization saved to jetsubstructureTest_extraction_visualization.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cab9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying on a different paper\n",
    "# 1. Define a concise prompt\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "\n",
    "Extract mentions of names of datasets, size in file counts, number of events and disk space size in bytes from scientific texts.\n",
    "Use exact text for extractions. Do not paraphrase. \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# 2. Provide a high-quality example to guide the model\n",
    "examples = [\n",
    "    lx.data.ExampleData(\n",
    "        text=(\n",
    "            \"Our jet substructure study is based on the Jet Primary Dataset [76], \"\n",
    "            \"which is a subset of the full open data release with events that pass a predefined set \"\n",
    "            \"of single-jet and multi-jet triggers. There are 1664 AOD files in the Jet Primary Dataset, corresponding to 20,022,826 events \"\n",
    "            \"and 2.0 Terabytes of disk space.\"\n",
    "        ),\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"file count\",\n",
    "                extraction_text=\"1664 AOD files\",\n",
    "                attributes={\"type\": \"count\"}, \n",
    "\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"data set\",\n",
    "                extraction_text=\"Jet Primary Dataset\",\n",
    "                attributes={\"type\": \"data set\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"disk space\",\n",
    "                extraction_text=\"2.0 Terabytes of disk space\",\n",
    "                attributes={\"type\": \"disk space\"},\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"number of events\",\n",
    "                extraction_text=\"20,022,826 events\",\n",
    "                attributes={\"type\": \"count\"},\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "# 3. Run the extraction on your input text\n",
    "input_text = alltext\n",
    "\n",
    "\n",
    "result = lx.extract(\n",
    "    text_or_documents=input_text,\n",
    "    prompt_description=prompt,\n",
    "    examples=examples,\n",
    "    model_id=\"gemini-2.5-flash\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and visualize the results\n",
    "lx.io.save_annotated_documents([result], output_name=\"stableDiffusionTest_extraction.jsonl\", output_dir=\".\")\n",
    "\n",
    "# Generate the interactive visualization\n",
    "html_content = lx.visualize(\"stableDiffusionTest_extraction.jsonl\")\n",
    "with open(\"stableDiffusionTest_extraction.html\", \"w\", encoding='utf-8') as f:\n",
    "    if hasattr(html_content, 'data'): #Check if the content has a data attribute\n",
    "        f.write(html_content.data)  \n",
    "    else:\n",
    "        f.write(html_content)\n",
    "\n",
    "print(\"Interactive visualization saved to stableDiffusionTest_extraction_visualization.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
